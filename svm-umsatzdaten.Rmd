---
title: "Support Vector Machine"
output: html_notebook
---


## Imports

```{r}
# Importing Function Packages
library(readr)
library(e1071)
library(Metrics)
library(dplyr)
library(ggplot2)

# Importing Data
house_pricing <- read_csv("https://raw.githubusercontent.com/opencampus-sh/sose20-datascience/master/house_pricing_test.csv")
```


## Aufteilung des Datensatzes in Trainings- und Testdaten

```{r}
# Zufallszähler setzen (um die zufällige Partitionierung bei jedem Durchlauf gleich zu halten)
set.seed(1)

# Zufällige Ziehung Indizes für die Zeilen des Datensatzes, die dem Traininsdatensatz zugeordnet werden
indices_train <- sample(seq_len(nrow(umsatzdaten)), size = floor(0.80 * nrow(umsatzdaten)))

# Definition des Trainings- und Testdatensatz durch Selektion bzw. Deselektion der entsprechenden Datenzeilen
train_dataset <- train_dataset_org <- umsatzdaten[indices_train, ]
test_dataset <- umsatzdaten[-indices_train, ]
```


## Data Preparation

```{r}
# Uncomment the following line to check the correctness of the code with a small (and computationally fast) training data set
train_dataset <- sample_frac(train_dataset_org, .10)
```


## Training the SVM

```{r}
# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(Umsatz ~ as.factor(wochentag), train_dataset)
```

Entferne Spalten die NA enthalten
```{r}
train_dataset$Wettercode <- NULL
train_dataset$wetterzustand <- NULL
train_dataset$Temperatur <- NULL
train_dataset$Bewoelkung <- NULL
train_dataset$Windgeschwindigkeit <- NULL
```

Support Vector Machine für verkleinerten Datensatz
```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, Umsatz ~ as.factor(Warengruppe) + as.factor(wochentag) + jahreszeit + KielerWoche, data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
```

Support Vector Machine für kompletten Datensatz
```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, Umsatz ~ as.factor(Warengruppe) + as.factor(wochentag) + jahreszeit + KielerWoche, data=train_dataset_org,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
```


## Checking the Prediction Quality

```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
pred_train
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$Umsatz, pred_train)
```



```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```


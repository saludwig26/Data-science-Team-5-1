---
title: "Project"
author: "Manuel Alejandro"
date: "5/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r}
library(readr)
library(lubridate)
library(ggplot2)
library(Metrics)
library(dplyr)
library(zoo)
library(e1071)
```
#### Installation von Python und der für TensorFlow benötigten Pakete (nur einmalig nötig) ###
```{r}
library(reticulate)

# Installation von miniconda (falls nicht vorhanden)
install_miniconda()

# Anlegen einer speziellen Python Umgebung
conda_create("r-reticulate")

# Installieren der Pakete in der angelegten Umgebung
conda_install("r-reticulate", "pandas")
conda_install("r-reticulate", "numpy")
conda_install("r-reticulate", "tensorflow")

# Verwenden der speziellen Python Umgebung die zuvor erstellt wurde
use_condaenv("r-reticulate")

```

```{r}
umsatzdaten <- read_csv("umsatzdaten_gekuerzt.csv")
```
Erstellung der Variable mit Wochentag
```{r}
# Berechnung der Wochentage
umsatzdaten$wochentag <- weekdays(umsatzdaten$Datum)

# Umwandlung von 'wochentag" in eine Faktor-Variable mit einer vorgegeben Sortierung der Level (Kategorien)
umsatzdaten$wochentag <- factor(umsatzdaten$wochentag, levels=c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))

```

Alle Warengruppen eines Tages zusammen fügen
```{r}

```

Erstellung der Variable mit Jahreszeit
```{r}
# Berechnung der Jahresqrt
yq <- as.yearqtr(as.yearmon(umsatzdaten$Datum, "%m/%d/%Y") + 1/12)
# Berechnung der Jahreszeit
umsatzdaten$jahreszeit <- factor(format(yq, "%q"), levels = 1:4, 
      labels = c("Winter", "Frueling", "Sommer", "Herbst"))


```

Erstellung der Variable mit Feiertage 
```{r}
#Einbinden der Bibliothek mit dr Funktion isHoliday:
detach("package:timeDate", unload = TRUE)
library(RQuantLib)

#Zeige deutsche Feiertage an:
getHolidayList("Germany", as.Date("2013-01-01"), as.Date("2020-01-01"))

#Füge die Feiertage "Himmelfahrt", "Pfingsten", "Tag deutscher Einheit" und "Reformationstag" zwischen 2013 und 2022 hinzu:
further_holidays <- (as.Date(c("2013-10-03", "2014-10-03", "2015-10-03", "2016-10-03", "2017-10-03", "2018-10-03", "2019-10-03", "2020-10-03", "2021-10-03", "2017-10-31", "2018-10-31", "2019-10-31", "2020-10-31", "2021-10-31", "2022-10-31", "2013-05-09", "2014-05-29", "2015-05-14", "2016-05-05", "2017-05-25", "2018-05-10", "2019-05-30", "2020-05-21", "2021-05-13", "2022-05-26", "2013-05-20", "2014-06-09", "2015-05-25", "2016-05-16", "2017-06-05", "2018-05-21", "2019-06-10", "2020-06-01", "2021-05-24", "2022-06-06", "2013-12-26", "2014-12-26", "2015-12-26", "2016-12-26", "2017-12-26", "2018-12-26", "2019-12-26", "2020-12-26", "2021-12-26", "2022-12-26")))
addHolidays("Germany", further_holidays)

#Erstelle neue Spalte mit dem Wert für Feiertag (Wochenenden ausgenommen):
umsatzdaten$holiday <- isHoliday("Germany", umsatzdaten$Datum) & !isWeekend("Germany", umsatzdaten$Datum)

View(umsatzdaten)
```

Langes Wochendende Vorher und nachher
Feiertag am Wochenende
```{r}




```

hat der Bäcker an manchen Tagen geschlossen = kein Umsatz
Vorher/nachher mehr umsatz 
```{r}
detach("package:RQuantLib", unload = TRUE)
library(timeDate)
all_dates <- tibble(Datum = as.Date(timeSequence(as.Date("2013-07-01"),as.Date("2019-06-03"))))

missing_dates <- anti_join(all_dates, umsatzdaten)


detach("package:timeDate", unload = TRUE)
library(RQuantLib)
missing_dates$holiday <- isHoliday("Germany", missing_dates$Datum)
missing_dates$WochentagMoFr <- !isWeekend("Germany", missing_dates$Datum)

```

Schulferien
```{r}
#detach("package:RQuantLib", unload = TRUE)
library(timeDate)

#Erstelle Vektor mit Datum für jeden Tag im Zeitraum der Umsatzdatentabelle
all_dates <- tibble(Datum = as.Date(timeSequence(as.Date("2013-07-01"),as.Date("2019-06-03"))))

#Daten der Schulferien in Schleswig-Holstein im Zeitraum der Umsatzdatentabelle
schulferien <- tibble(Datum = as.Date(c( timeSequence(as.Date("2013-07-01"), as.Date("2013-08-03")),
timeSequence(as.Date("2013-10-04"), as.Date("2013-10-18")),
timeSequence(as.Date("2013-12-23"), as.Date("2014-01-06")),
                                         timeSequence(as.Date("2014-04-16"), as.Date("2014-05-02")),
timeSequence(as.Date("2014-07-14"), as.Date("2014-08-23")), timeSequence(as.Date("2014-10-13"), as.Date("2014-10-25")),
timeSequence(as.Date("2014-12-22"), as.Date("2015-01-06")),
                                         
timeSequence(as.Date("2015-03-24"), as.Date("2015-04-09")),
timeSequence(as.Date("2015-07-25"), as.Date("2015-09-03")),
timeSequence(as.Date("2015-10-17"), as.Date("2015-10-29")), timeSequence(as.Date("2015-12-23"), as.Date("2016-01-06")),
                                         timeSequence(as.Date("2016-04-16"), as.Date("2016-05-02")),
timeSequence(as.Date("2016-07-14"), as.Date("2016-08-23")),
timeSequence(as.Date("2016-10-13"), as.Date("2016-10-25")), timeSequence(as.Date("2016-12-22"), as.Date("2017-01-06")),
                                         
timeSequence(as.Date("2017-04-07"), as.Date("2017-04-21")),
timeSequence(as.Date("2017-07-24"), as.Date("2017-09-02")),
timeSequence(as.Date("2017-10-16"), as.Date("2017-10-27")),
timeSequence(as.Date("2017-12-21"), as.Date("2018-01-06")),
                                         
timeSequence(as.Date("2018-03-29"), as.Date("2018-04-13")),
timeSequence(as.Date("2018-07-09"), as.Date("2018-08-18")),
timeSequence(as.Date("2018-10-01"), as.Date("2018-10-19")),
timeSequence(as.Date("2018-12-21"), as.Date("2019-01-04")),
                                         
timeSequence(as.Date("2019-04-04"), as.Date("2019-04-18"))
)))
#Füge Kalender für Schulferien in umsatzdaten ein mit den Werten TRUE und FALSE
schulferien$schulferien <- TRUE
schulferien <- left_join(all_dates, schulferien)
schulferien$schulferien <- !is.na(schulferien$schulferien)
umsatzdaten <- left_join(umsatzdaten, schulferien)
```


Kieler Woche:
1. Einbinden benötigter Bibliotheken
2. Einlesen der Daten
3. Zusammenführen der Daten
```{r}
library(readr)
library(dplyr)

#umsatzdaten <- read_csv("umsatzdaten_gekuerzt.csv")
kiwo <- read_csv("kiwo.csv")


umsatzdaten <- left_join(umsatzdaten, kiwo)
View(umsatzdaten)
```


Einbindung Wetterdaten
```{r}
library(readr)
library(dplyr)

wetter <- read_csv("wetter.csv")
View(wetter)

umsatzdaten<- left_join(umsatzdaten, wetter)
View(umsatzdaten)



```



```Overfitting with linear regression
ToDo: Noch updaten!!
Importing Function Packages

```{r}
library(dplyr)
library(readr)
library(lubridate)
library(broom)
library(Metrics)
```

Datensatz in Training und Test Data teilen
https://duttashi.github.io/blog/splitting-a-data-frame-into-training-and-testing-sets-in-r/


```{r}
library(caTools)
# To set a seed use the function set.seed()
set.seed(123)

#70% training and 30% testing data
# umsatzdaten$spl will create a new column in the umsatzdaten dataset.</code>
umsatzdaten$spl3=sample.split(umsatzdaten$Datum,SplitRatio=0.7)

View(umsatzdaten)
#Training data set
train=subset(umsatzdaten, umsatzdaten$spl==TRUE)
# where <i>spl== TRUE</i> means to add only those rows that have value true for spl in the training dataframe

# you will see that this dataframe has all values where umsatzdaten$spl==TRUE
View(train)
write.csv(train,"train.csv", row.names = TRUE)
#Similarly, to create the testing dataset,
test=subset(umsatzdaten, umsatzdaten$spl==FALSE) 
View(test)
write.csv(test,"test.csv", row.names = TRUE)
#where <i>spl== FALSE </i> means to add only those rows that have value true for spl in the training dataframe

#> View(test) # you will see that this dataframe has all values where iris$spl==FALSE
```

Importing Training and Test Data


```{r}
baecker_umsatzdaten_train <- read_csv("train.csv")
baecker_umsatzdaten_test <- read_csv("test.csv")
```

Estimating (Training) Models

(Alle Warengruppen getrennt anschauen)
```{r}
mod1 <- lm(Umsatz ~ wochentag, umsatzdaten)
mod2 <- lm(Umsatz ~ as.factor(Warengruppe), umsatzdaten)
mod3 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag), umsatzdaten)
mod4 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche, umsatzdaten)

mod5 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur, umsatzdaten)
mod6 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+holiday, umsatzdaten) 
#mod7 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+holiday+as.factor(jahreszeit), umsatzdaten) #Fehler

mod8 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+holiday+Bewoelkung, umsatzdaten) 

```


```{r}
summary(mod1)
plot(mod1)
summary(mod2)
plot(mod2)
summary(mod3)
summary(mod4)
summary(mod5)
summary(mod6)
#summary(mod7)
summary(mod8)
```

```{r}

glance(mod1)
glance(mod2)
```

Preparation of Model Results
```{r}
rbind(glance(mod1), glance(mod2), glance(mod3), glance(mod4), glance(mod5), glance(mod6), glance(mod7))
```

Model Prediction Quality for the Training Data Using the Mean Absolute Error
```{r}
rbind(mae(house_pricing_train$price, predict(mod1)),
      mae(house_pricing_train$price, predict(mod2)),
      mae(house_pricing_train$price, predict(mod3)),
      mae(house_pricing_train$price, predict(mod4)),
      mae(house_pricing_train$price, predict(mod5)),
      mae(house_pricing_train$price, predict(mod6)),
      mae(house_pricing_train$price, predict(mod7)))
```


Model Prediction Quality for the Training Data Using the Mean Absolute Percentage Error
```{r}
rbind(mape(house_pricing_train$price, predict(mod1)),
      mape(house_pricing_train$price, predict(mod2)),
      mape(house_pricing_train$price, predict(mod3)),
      mape(house_pricing_train$price, predict(mod4)),
      mape(house_pricing_train$price, predict(mod5)),
      mape(house_pricing_train$price, predict(mod6)),
      mape(house_pricing_train$price, predict(mod7)))
```

Model Prediction Quality for the (Unknown) Test Data Using the Mean Absolute Percentage Error
```{r}
rbind(mape(house_pricing_test$price, predict(mod1, newdata=house_pricing_test)),
      mape(house_pricing_test$price, predict(mod2, newdata=house_pricing_test)),
      mape(house_pricing_test$price, predict(mod3, newdata=house_pricing_test)),
      mape(house_pricing_test$price, predict(mod4, newdata=house_pricing_test)),
      mape(house_pricing_test$price, predict(mod5, newdata=house_pricing_test)),
      mape(house_pricing_test$price, predict(mod6, newdata=house_pricing_test)),
      mape(house_pricing_test$price, predict(mod7, newdata=house_pricing_test)))


```


## Training the SVM  -- TO DO!
```{r}
# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(price ~ bathrooms, train_dataset)
```

```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, price ~ bedrooms + bathrooms + sqft_living + zipcode, data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
```

## Checking the Prediction Quality -- TO DO!
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$price, pred_train)
```


```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(test_dataset$price, pred_test)
```


---
title: "Project"
author: "Data Science Team 5"
date: "5/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
 
```

```{r}
library(readr)
library(lubridate)
library(ggplot2)
library(Metrics)
library(dplyr)
library(zoo)
library(e1071)
```


```{r}
umsatzdaten <- read_csv("umsatzdaten_gekuerzt.csv")
```

Vorhersage
```{r}
#Bestimme das zu vorhersagende Datum und schreibe es in den Datensatz ein
vorhersage_date <- as.Date("2019-06-04")

umsatzdaten <- rbind(umsatzdaten, tibble(Datum = rep(vorhersage_date,6), Warengruppe = (1:6), Umsatz=NA))
```


Erstellung der Variable mit Wochentag
```{r}
# Berechnung der Wochentage
umsatzdaten$wochentag <- weekdays(umsatzdaten$Datum)

# Umwandlung von 'wochentag" in eine Faktor-Variable mit einer vorgegeben Sortierung der Level (Kategorien)
umsatzdaten$wochentag <- factor(umsatzdaten$wochentag, levels=c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))

```

Erstellung der Variable mit Jahreszeit
```{r}
# Berechnung der Jahresqrt
yq <- as.yearqtr(as.yearmon(umsatzdaten$Datum, "%m/%d/%Y") + 1/12)
# Berechnung der Jahreszeit
umsatzdaten$jahreszeit <- factor(format(yq, "%q"), levels = 1:4, 
      labels = c("Winter", "Frueling", "Sommer", "Herbst"))
rm(yq)
```
Erstellung der Variable "monat"
```{r}
umsatzdaten <- mutate(umsatzdaten, monat = factor(format(Datum, "%m")))
```

Erstellung der Variable mit Feiertage 
```{r}
holidays <- read.csv("Holiday_List")
holidays$Datum <- as.Date(holidays$Datum)
umsatzdaten <- left_join(umsatzdaten, holidays)
umsatzdaten$holiday <- !is.na(umsatzdaten$holiday)
umsatzdaten$sylvester <- !is.na(umsatzdaten$sylvester)
rm(holidays)
```

Langes Wochendende (Liegt vor dem Saturday oder nach dem Sunday ein Feiertag? bzw. ist Montag oder Freitag ein Feiertag?)
```{r}
#Ist Monday oder Freitag == umsatzdaten$holiday == "TRUE"
umsatzdaten$VerlaengertesWE_Mo<- umsatzdaten$wochentag == "Monday" & umsatzdaten$holiday == "TRUE"
umsatzdaten$VerlaengertesWE_Fr<- umsatzdaten$wochentag == "Friday" & umsatzdaten$holiday == "TRUE"
```

Schulferien
```{r}
schulferien <- read.csv("Schulferien")
schulferien$Datum <- as.Date(schulferien$Datum)
umsatzdaten <- left_join(umsatzdaten, schulferien)
umsatzdaten$schulferien <- !is.na(umsatzdaten$schulferien)
rm(schulferien)
```

Kieler Woche:
```{r}
kiwo <- read_csv("kiwo.csv")
umsatzdaten$KielerWoche <- NULL
umsatzdaten <- left_join(umsatzdaten, kiwo)
umsatzdaten$KielerWoche <- !is.na(umsatzdaten$KielerWoche)
rm(kiwo)
```


Einbindung Wetterdaten
```{r}
library(readr)
library(dplyr)

wetter <- read_csv("wetter.csv")

wetter[is.na(wetter)] <-0
str(wetter)

umsatzdaten<- left_join(umsatzdaten, wetter)

#warm (TRUE) oder kalt (FALSE)
umsatzdaten$warmTemp<-ifelse(umsatzdaten$Temperatur > 18,TRUE,FALSE)


## Umformen der numerischen Variable Windgeschwindigkeit in Faktorvariabel 
umsatzdaten$Windgeschwindigkeit <- cut(umsatzdaten$Windgeschwindigkeit, breaks = c(0,10.7,20.7,37), labels=c("Brise", "Wind","Sturm"), right=FALSE)
umsatzdaten$Windgeschwindigkeit[1:10]


## Umformen der numerischen Variable Temperatur
umsatzdaten$Temperatur <- as.numeric(as.character(umsatzdaten$Temperatur))
umsatzdaten$Temperatur<- cut(umsatzdaten$Temperatur, breaks = c(-20,1,11,21,31,45), labels=c("eisig", "kalt", "moderat", "sommerlich", "heiß"), right=FALSE)
```



```{r}
#Wettercode - Umformen der numerischen Variable Wettercode in Faktorvariabel 
umsatzdaten$Wettercode <- as.numeric(as.character(umsatzdaten$Wettercode))
umsatzdaten$Wettercode <- cut(umsatzdaten$Wettercode, breaks = c(0,14,99), labels=c("Trocken","RegenGewitter"), right=FALSE)

View(umsatzdaten) 


#keineBeobachtung 0
#Bewölkung (1-3)
#DunstStaub (4-10)
#Nebel 11-12
#Wetterleuchte 13
#Niederschlag 14-
#Gewitter 17
#BoeeTornado 18-19
#EndeRegSchnSchau 20-29
#Sandsturm 30-35
#Schnee 36-39
#Nebel2 40-49
#Sprühregen (50-59
#Regen (60-67)
#Schneeregen 68-69
#Schnee2  70-75
#Schnee_mooNebel 76-78
#Eiskorn 79
#Regenschauer (80-82
#Schneeregenschauer 83-86
#Graupelschauer 87-88
#Hagelschauer 89-90
#Gewitter2(91-99)

```



```Overfitting with linear regression
Importing Function Packages

```{r}
library(dplyr)
library(readr)
library(lubridate)
library(broom)
library(Metrics)
```

Datensatz in Training und Test Data teilen
https://duttashi.github.io/blog/splitting-a-data-frame-into-training-and-testing-sets-in-r/


```{r}
# library(caTools)
# # To set a seed use the function set.seed()
# set.seed(123)
# 
# #70% training and 30% testing data
# # umsatzdaten$spl will create a new column in the umsatzdaten dataset.</code>
# umsatzdaten$spl3=sample.split(umsatzdaten$Datum,SplitRatio=0.7)
# 
# View(umsatzdaten)
# #Training data set
# train=subset(umsatzdaten, umsatzdaten$spl3==TRUE)
# # where <i>spl== TRUE</i> means to add only those rows that have value true for spl in the training dataframe
# 
# # you will see that this dataframe has all values where umsatzdaten$spl==TRUE
# View(train)
# write.csv(train,"train.csv", row.names = TRUE)
# #Similarly, to create the testing dataset,
# test=subset(umsatzdaten, umsatzdaten$spl3==FALSE) 
# View(test)
# write.csv(test,"test.csv", row.names = TRUE)
# #where <i>spl== FALSE </i> means to add only those rows that have value true for spl in the training dataframe

#> View(test) # you will see that this dataframe has all values where iris$spl==FALSE
```

```{r}
# Uncomment the following line to check the correctness of the code with a small (and computationally fast) training data set
train_dataset <- sample_frac(train, .10)
```

Importing Training and Test Data
```{r}
baecker_umsatzdaten_train <- read_csv("train.csv")
baecker_umsatzdaten_test <- read_csv("test.csv")
```

Estimating (Training) Models
(Alle Warengruppen getrennt anschauen)
```{r}
mod0 <- lm(Umsatz ~ , umsatzdaten)
mod1 <- lm(Umsatz ~ wochentag, umsatzdaten)
mod2 <- lm(Umsatz ~ as.factor(Warengruppe), umsatzdaten)
mod3 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag), umsatzdaten)
mod4 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche, umsatzdaten)
mod5 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur, umsatzdaten)
mod6 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit, umsatzdaten)
mod7 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit+dayoff_after, umsatzdaten)
mod8 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit+dayoff_after+dayoff_b4, umsatzdaten)
mod9 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit+dayoff_after+dayoff_b4+jahreszeit, umsatzdaten)
mod10 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit+dayoff_after+dayoff_b4+jahreszeit+Bewoelkung, umsatzdaten)
<<<<<<< HEAD
mod11 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit+dayoff_after+dayoff_b4+jahreszeit+Bewoelkung+holiday, umsatzdaten)
mod12 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit+dayoff_after+dayoff_b4+jahreszeit+Bewoelkung+holiday+dayoff_after_holiday, umsatzdaten)
mod13 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+Windgeschwindigkeit+dayoff_after+dayoff_b4+jahreszeit+Bewoelkung+holiday+dayoff_after_holiday+dayoff_b4_holiday, umsatzdaten)

mod6 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+holiday, umsatzdaten) 
#mod7 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+holiday+as.factor(jahreszeit), umsatzdaten) #Fehler

mod8 <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+holiday+Bewoelkung, umsatzdaten) 

mod9  <- lm(Umsatz ~ as.factor(Warengruppe)+ as.factor(wochentag)+ KielerWoche+ Temperatur+holiday+Bewoelkung+as.logical(dayoff_after)+ as.logical(dayoff_b4) + schulferien, umsatzdaten) 
```


```{r}
summary(mod0)
summary(mod1)
plot(mod1)
summary(mod2)
plot(mod2)
summary(mod3)
summary(mod4)
summary(mod5)
summary(mod6)
summary(mod7)
summary(mod8)
summary(mod9)
summary(mod10)
<<<<<<< HEAD
summary(mod11)
summary(mod12)
summary(mod13)
=======
>>>>>>> baf365bd4af70a91a8c5d67bd1c199029bd948eb
```

```{r}

glance(mod1)
glance(mod2)
glance(mod13)

```

Preparation of Model Results
```{r}
rbind(glance(mod1), glance(mod2), glance(mod3), glance(mod4), glance(mod5), glance(mod6), glance(mod7), glance(mod8) ,glance(mod9), glance(mod10), glance(mod11),glance(mod12), glance(mod13), )
```

Model Prediction Quality for the Training Data Using the Mean Absolute Error
```{r}
rbind(mae(train$Umsatz, predict(mod1)),
      mae(train$Umsatz, predict(mod2)),
      mae(train$Umsatz, predict(mod3)),
      mae(train$Umsatz, predict(mod4)),
      mae(train$Umsatz, predict(mod5)),
      mae(train$Umsatz, predict(mod6)),
      mae(train$Umsatz, predict(mod8)))
```


Model Prediction Quality for the Training Data Using the Mean Absolute Percentage Error
```{r}
rbind(mape(house_pricing_train$price, predict(mod1)),
      mape(house_pricing_train$price, predict(mod2)),
      mape(house_pricing_train$price, predict(mod3)),
      mape(house_pricing_train$price, predict(mod4)),
      mape(house_pricing_train$price, predict(mod5)),
      mape(house_pricing_train$price, predict(mod6)),
      mape(house_pricing_train$price, predict(mod7)))

rbind(mape(train$Umsatz, predict(mod1)),
      mape(train$Umsatz, predict(mod2)),
      mape(train$Umsatz, predict(mod3)),
      mape(train$Umsatz, predict(mod4)),
      mape(train$Umsatz, predict(mod5)),
      mape(train$Umsatz, predict(mod6)),
      mape(train$Umsatz, predict(mod8)))
```

Model Prediction Quality for the (Unknown) Test Data Using the Mean Absolute Percentage Error
```{r}
rbind(mape(test$Umsatz, predict(mod1, newdata=test)),
      mape(test$Umsatz, predict(mod2, newdata=test)),
      mape(test$Umsatz, predict(mod3, newdata=test)))

    #mape(test$Umsatz, predict(mod4, newdata=test))),
     # mape(test$Umsatz, predict(mod5, newdata=test)),
      #mape(test$Umsatz, predict(mod6, newdata=test)),
      #mape(test$Umsatz, predict(mod8, newdata=test)))

      
   
#rbind(mape(house_pricing_test$price, predict(mod1, newdata=house_pricing_test)),
#      mape(house_pricing_test$price, predict(mod2, newdata=house_pricing_test)),
 #     mape(house_pricing_test$price, predict(mod3, newdata=house_pricing_test)),
  #    mape(house_pricing_test$price, predict(mod4, newdata=house_pricing_test)),
   #   mape(house_pricing_test$price, predict(mod5, newdata=house_pricing_test)),
    #  mape(house_pricing_test$price, predict(mod6, newdata=house_pricing_test)),
     # mape(house_pricing_test$price, predict(mod7, newdata=house_pricing_test)))

```


## Training the SVM  -- TO DO!
```{r}

# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(Umsatz ~ Warengruppe, train_dataset)
model_svm <- svm(Umsatz ~ Warengruppe, train)
```

```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, Umsatz ~ Warengruppe, data=train,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
```

## Checking the Prediction Quality -- TO DO!
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train)
# Calculating the prediction quality for the training data using the MAPE
mape(train$Umsatz, pred_train)
```


```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test)
# Calculating the prediction quality for the training data using the MAPE
mape(test$Umsatz, pred_test)
```




#TO DO
Estimation of Neural Net Data Preparation
### Vorbereitung der Umgebung ###
```{r}
# Falls nicht installiert ggf. ausausführen
#install.packages("fastDummies")

# Umgebungsvariablen löschen
remove(list = ls())

# Einbinden benötigter Funktionsbibliotheken
library(readr)
library(fastDummies)

```


#TO DO
### Funktionsdefinitionen ###

```{r}
#' Title Fast creation of normalized variables
#' Quickly create normalized columns from numeric type columns in the input data. This function is useful for statistical analysis when you want normalized columns rather than the actual columns.
#'
#' @param .data An object with the data set you want to make normalized columns from.
#' @param norm_values Dataframe of column names, means, and standard deviations that is used to create corresponding normalized variables from.
#'
#' @return A data.frame (or tibble or data.table, depending on input data type) with same number of rows an dcolumns as the inputted data, only with normalized columns for the variables indicated in the norm_values argument.
#' @export
#'
#' @examples
norm_cols <- function (.data, norm_values = NULL) {
  for (i in 1:nrow(norm_values)  ) {
    .data[[norm_values$name[i]]] <- (.data[[norm_values$name[i]]] - norm_values$mean[i]) / norm_values$sd[i]
  }
  return (.data)
}


#' Title Creation of a Dataframe including the Information to Standardize Variables
#' This function is meant to be used in combination with the function norm_cols
#'
#' @param .data A data set including the variables you want to get the means and standard deviations from.
#' @param select_columns A vector with a list of variable names for which you want to get the means and standard deviations from.
#'
#' @return A data.frame (or tibble or data.table, depending on input data type) including the names, means, and standard deviations of the variables included in the select_columns argument.
#' @export
#'
#' @examples
get.norm_values <- function (.data, select_columns = NULL) {
  result <- NULL
  for (col_name in select_columns) {
    mean <- mean(.data[[col_name]], na.rm = TRUE)
    sd <- sd(.data[[col_name]], na.rm = TRUE)
    result <- rbind (result, c(mean, sd))
  }
  result <- as.data.frame(result, stringsAsFactors = FALSE)
  result <- data.frame (select_columns, result, stringsAsFactors = FALSE)
  names(result) <- c("name", "mean", "sd")
  return (result)
}

```

#TO DO
### Datenaufbereitung ###

```{r}
# Rekodierung von kategoriellen Variablen (zu Dummy-Variablen)
dummy_list <- c("view", "condition")
house_pricing_dummy = dummy_cols(house_pricing, dummy_list)

# Definition von Variablenlisten für die Dummies, um das Arbeiten mit diesen zu erleichtern
condition_dummies = c('condition_1', 'condition_2', 'condition_3', 'condition_4', 'condition_5')
view_dummies = c('view_0', 'view_1', 'view_2', 'view_3','view_4')


# Standardisierung aller Feature Variablen und der Label Variable
norm_list <- c("price", "sqft_lot", "bathrooms", "grade", "waterfront", view_dummies, condition_dummies) # Liste aller Variablen
norm_values_list <- get.norm_values(house_pricing_dummy, norm_list)    # Berechnung der Mittelwerte und Std.-Abw. der Variablen
house_pricing_norm <- norm_cols(house_pricing_dummy, norm_values_list) # Standardisierung der Variablen
```

#TO DO
### Definition der Feaure-Variablen und der Label-Variable

```{r}
# Definition der Features (der unabhängigen Variablen auf deren Basis die Vorhersagen erzeugt werden sollen)
features = c('sqft_lot', 'waterfront', 'grade', 'bathrooms', view_dummies, condition_dummies)
# Definition der Label-Variable (der abhaengigen Variable, die vorhergesagt werden soll) sowie
label = 'price_norm'
```

#TO DO
### Definition von Trainings- und Testdatensatz ###

```{r}
# Zufallszähler setzen, um die zufällige Partitionierung bei jedem Durchlauf gleich zu halten
set.seed(1)
# Bestimmung der Indizes des Traininsdatensatzes
train_ind <- sample(seq_len(nrow(house_pricing_norm)), size = floor(0.80 * nrow(house_pricing_norm)))

# Teilen in Trainings- und Testdatensatz
train_dataset = house_pricing_norm[train_ind, features]
test_dataset = house_pricing_norm[-train_ind, features]

# Selektion der Variable, die als Label definiert wurde
train_labels = house_pricing_norm[train_ind, label]
test_labels = house_pricing_norm[-train_ind, label]


```

#TO DO
```{r}
# Import Libraries
library(reticulate)


# Importing Data
data <- mpg

```


```{python}
year = r.data['year']

```


```{r}
table(py$year)

```



hat der Bäcker an manchen Tagen geschlossen = kein Umsatz
Vorher/nachher mehr umsatz 
```{r}
# #detach("package:RQuantLib", unload = TRUE)
# library(timeDate)
# all_dates <- tibble(Datum = as.Date(timeSequence(as.Date("2013-07-01"),as.Date("2019-06-03"))))
# 
# missing_dates <- anti_join(all_dates, umsatzdaten)
# 
# 
# detach("package:timeDate", unload = TRUE)
# library(RQuantLib)
# missing_dates$holiday <- isHoliday("Germany", missing_dates$Datum)
# missing_dates$WochentagMoFr <- !isWeekend("Germany", missing_dates$Datum)
# 
# detach("package:RQuantLib", unload = TRUE)
# library(timeDate)
# all_dates <- tibble(Datum = as.Date(timeSequence(as.Date("2013-07-01"),as.Date("2019-06-03"))))
# 
# missing_dates <- anti_join(all_dates, umsatzdaten)
# 
# 
# detach("package:timeDate", unload = TRUE)
# library(RQuantLib)
# missing_dates$holiday <- isHoliday("Germany", missing_dates$Datum)
# missing_dates$WochentagMoFr <- !isWeekend("Germany", missing_dates$Datum)
# 
# 
# dayoff_after <- tibble(Datum = missing_dates$Datum + 1, dayoff_after=TRUE)
# dayoff_b4 <- tibble(Datum = missing_dates$Datum - 1, dayoff_b4=TRUE)
# umsatzdaten <- left_join(umsatzdaten, dayoff_after)
# umsatzdaten <- left_join(umsatzdaten, dayoff_b4)
# 
# #Setze für NA in der Tabelle den Wert FALSE ein
# umsatzdaten$dayoff_after <- !is.na(umsatzdaten$dayoff_after)
# umsatzdaten$dayoff_b4 <- !is.na(umsatzdaten$dayoff_b4)
# 
# 
# #Tag vor oder nachdem der Bäcker an einem FEIERTAG geschlossen hatte
# dayoff_after_holiday <- tibble(Datum = missing_dates$Datum[missing_dates$holiday==TRUE] + 1, dayoff_after_holiday=TRUE)
# dayoff_b4_holiday <- tibble(Datum = missing_dates$Datum[missing_dates$holiday==TRUE] - 1, dayoff_b4_holiday=TRUE)
# umsatzdaten <- left_join(umsatzdaten, dayoff_after_holiday)
# umsatzdaten <- left_join(umsatzdaten, dayoff_b4_holiday)
# 
# #Setze für NA in der Tabelle den Wert FALSE ein
# umsatzdaten$dayoff_after_holiday <- !is.na(umsatzdaten$dayoff_after_holiday)
# umsatzdaten$dayoff_b4_holiday <- !is.na(umsatzdaten$dayoff_b4_holiday)
# 
# View(umsatzdaten)
```

```{r}
#Ignore!
#Abweichung der Temperatur von der durchschnittstemperatur in dem jeweiligen Monat
# First we filter the year 2013
umsatzdaten_y13 <- umsatzdaten[which(year(umsatzdaten$Datum) == 2013),]
# Now we add a column with the month
# Check the "Read date and time variables" and the "mutate" tutorials
umsatzdaten_y13 <- mutate(umsatzdaten_y13, Month = factor(format(Datum, "%m")))
#str(umsatzdaten_y13)
View(umsatzdaten_y13)

umsatzdaten_2013 <-    
    group_by(umsatzdaten_y13, Month) %>% 
    summarise(Month_avg = mean (Temperatur))

View(umsatzdaten_2013)

# First we filter the year 2013
umsatzdaten_y14 <- umsatzdaten[which(year(umsatzdaten$Datum) == 2014),]

# Now we add a column with the month
# Check the "Read date and time variables" and the "mutate" tutorials
umsatzdaten_y14 <- mutate(umsatzdaten_y14, Month = factor(format(Datum, "%m")))
#str(umsatzdaten_y14)
View(umsatzdaten_y14)

umsatzdaten_2014 <-    
    group_by(umsatzdaten_y14, Month) %>% 
    summarise(Month_avg = mean (Temperatur))

View(umsatzdaten_2014)


# First we filter the year 2013
umsatzdaten_y15 <- umsatzdaten[which(year(umsatzdaten$Datum) == 2015),]

# Now we add a column with the month
# Check the "Read date and time variables" and the "mutate" tutorials
umsatzdaten_y15 <- mutate(umsatzdaten_y15, Month = factor(format(Datum, "%m")))
#str(umsatzdaten_y15)
View(umsatzdaten_y15)

umsatzdaten_2015 <-    
    group_by(umsatzdaten_y15, Month) %>% 
    summarise(Month_avg = mean (Temperatur))

View(umsatzdaten_2015)



# First we filter the year 2016
umsatzdaten_y16 <- umsatzdaten[which(year(umsatzdaten$Datum) == 2016),]

# Now we add a column with the month
# Check the "Read date and time variables" and the "mutate" tutorials
umsatzdaten_y16 <- mutate(umsatzdaten_y16, Month = factor(format(Datum, "%m")))
#str(umsatzdaten_y16)
View(umsatzdaten_y16)

umsatzdaten_2016 <-    
    group_by(umsatzdaten_y16, Month) %>% 
    summarise(Month_avg = mean (Temperatur))

View(umsatzdaten_2016)




# First we filter the year 2017
umsatzdaten_y17 <- umsatzdaten[which(year(umsatzdaten$Datum) == 2017),]

# Now we add a column with the month
# Check the "Read date and time variables" and the "mutate" tutorials
umsatzdaten_y17 <- mutate(umsatzdaten_y17, Month = factor(format(Datum, "%m")))
#str(umsatzdaten_y17)
View(umsatzdaten_y17)

umsatzdaten_2017 <-    
    group_by(umsatzdaten_y17, Month) %>% 
    summarise(Month_avg = mean (Temperatur))

View(umsatzdaten_2017)


umsatzdaten_y18 <- umsatzdaten[which(year(umsatzdaten$Datum) == 2018),]

# Now we add a column with the month
# Check the "Read date and time variables" and the "mutate" tutorials
umsatzdaten_y18 <- mutate(umsatzdaten_y18, Month = factor(format(Datum, "%m")))
#str(umsatzdaten_y18)
View(umsatzdaten_y18)

umsatzdaten_2018 <-    
    group_by(umsatzdaten_y18, Month) %>% 
    summarise(Month_avg = mean (Temperatur))

View(umsatzdaten_2018)

umsatzdaten_y19 <- umsatzdaten[which(year(umsatzdaten$Datum) == 2019),]

# Now we add a column with the month
# Check the "Read date and time variables" and the "mutate" tutorials
umsatzdaten_y19 <- mutate(umsatzdaten_y19, Month = factor(format(Datum, "%m")))
#str(umsatzdaten_y19)
View(umsatzdaten_y19)

umsatzdaten_2019 <-    
    group_by(umsatzdaten_y19, Month) %>% 
    summarise(Month_avg = mean (Temperatur))

View(umsatzdaten_2019)

#Difference für Abweichung






umsatzdaten_y13$Value <- 2

# Now we group by the month column
umsatzdaten <- group_by(umsatzdaten_y13, Month)
summarize(umsatzdaten, Temperatur1 = mean(Temperatur))


umsatzdaten_y13 <- mean(umsatzdaten_y13$Temperatur if umsatzdaten_y13$Month == 7)
library(dplyr)

umsatzdaten_y13 %>% 
group_by(Month) %>% 
  summarize(m = mean(umsatzdaten_y13$Temperatur)
  mutate(mean(as.numeric(umsatzdaten_y13$Temperatur)))
  ###
  
 umsatzdaten_y13  <- umsatzdaten_y13  %>%  
    group_by(Month) %>% 
    mutate(MonthAve= mean (Temperatur)) 
  
 
View(umsatzdaten_y13)
summarize(m = mean(speed))


library(dplyr)

AbweiDurch<- umsatzdaten %>% 
    group_by(Month = format(as.Date(Datum), '%b-%Y')) %>%
    mean(umsatzdaten$Temperatur), )
View(umsatzdaten) 

umsatzdaten$Temperatur1<-mean(as.numeric(umsatzdaten$Temperatur)

AbweiDurch<- umsatzdaten %>% 
    group_by(Month = format(as.Date(Datum), '%b-%Y')) %>%
    mean(umsatzdaten$Temperatur), )

library(data.table)
setDT(umsatzdaten)[,lapply(.SD, function(x) if(length(na.omit(x)) >=15)
       mean(x, na.rm=TRUE) else NA_real_) ,
             by = .(Month= format(as.IDate(Datum), '%b-%Y'))]


AbweiDurch<- umsatzdaten %>% 
    group_by(Month = format(as.Date(Datum), '%b-%Y')) %>%
    mean(Temperatur, trim = 0, na.rm=FALSE)

library(dplyr)
library(lubridate)
umsatzdaten  %>% group_by(year(=floor_date(date(), "year")) %>%
   summarize(Temperatur1=sum(Temperatur))
str(umsatzdaten)

library(dplyr)

AbweiDurch<- umsatzdaten %>% 
    group_by(Month = format(as.Date(Datum), '%b-%Y')) %>%
    mean(umsatzdaten$Temperatur), )
View(umsatzdaten) 

umsatzdaten$Temperatur1<-mean(as.numeric(umsatzdaten$Temperatur)

AbweiDurch<- umsatzdaten %>% 
    group_by(Month = format(as.Date(Datum), '%b-%Y')) %>%
    mean(umsatzdaten$Temperatur), )

library(data.table)
setDT(umsatzdaten)[,lapply(.SD, function(x) if(length(na.omit(x)) >=15)
       mean(x, na.rm=TRUE) else NA_real_) ,
             by = .(Month= format(as.IDate(Datum), '%b-%Y'))]


AbweiDurch<- umsatzdaten %>% 
    group_by(Month = format(as.Date(Datum), '%b-%Y')) %>%
    mean(Temperatur, trim = 0, na.rm=FALSE)

library(dplyr)
library(lubridate)
umsatzdaten  %>% group_by(year(=floor_date(date(), "year")) %>%
   summarize(Temperatur1=sum(Temperatur))
str(umsatzdaten)
=======
```


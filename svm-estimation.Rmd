---
title: "Support Vector Machine"
output: html_notebook
---


## Imports

```{r}
# Importing Function Packages
library(readr)
library(e1071)
library(Metrics)
library(dplyr)
library(ggplot2)

# Importing Data
house_pricing <- read_csv("https://raw.githubusercontent.com/opencampus-sh/sose20-datascience/master/house_pricing_test.csv")
```


## Aufteilung des Datensatzes in Trainings- und Testdaten

```{r}
# Zufallsz채hler setzen (um die zuf채llige Partitionierung bei jedem Durchlauf gleich zu halten)
set.seed(1)

# Zuf채llige Ziehung Indizes f체r die Zeilen des Datensatzes, die dem Traininsdatensatz zugeordnet werden
indices_train <- sample(seq_len(nrow(house_pricing)), size = floor(0.80 * nrow(house_pricing)))

# Definition des Trainings- und Testdatensatz durch Selektion bzw. Deselektion der entsprechenden Datenzeilen
train_dataset <- train_dataset_org <- house_pricing[indices_train, ]
test_dataset <- house_pricing[-indices_train, ]
```


## Data Preparation

```{r}
# Uncomment the following line to check the correctness of the code with a small (and computationally fast) training data set
train_dataset <- sample_frac(train_dataset_org, .10)
```


## Training the SVM

```{r}
# Estimation of an SVM with optimized weighting parameters and given standard hyper parameters
# Typically not used; instead, the function svm_tune is used in order to also get a model with optimized hyper parameters
model_svm <- svm(price ~ bathrooms, train_dataset)
```

```{r}
# Estimation of various SVM (each with optimized weighting parameters) using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, price ~ bedrooms + bathrooms + sqft_living + zipcode, data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))
```


## Checking the Prediction Quality

```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$price, pred_train)
```

```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(test_dataset$price, pred_test)
```

